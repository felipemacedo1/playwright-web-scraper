"""
Web Scraper Module

M√≥dulo principal de scraping usando Playwright.
Coleta dados de p√°ginas web de forma automatizada e robusta.
"""

import logging
import time
from typing import List, Dict, Optional
from playwright.sync_api import sync_playwright, Browser, Page, BrowserContext

from .auto_detect import auto_detect_selectors

logger = logging.getLogger(__name__)


class WebScraper:
    """
    Scraper web usando Playwright (modo s√≠ncrono).
    
    Recursos:
    - Suporte a login com storage_state
    - Scroll autom√°tico at√© o fim da p√°gina
    - Extra√ß√£o gen√©rica de dados
    - Auto-detec√ß√£o de seletores CSS
    - Tratamento de erros robusto
    """
    
    # Seletores gen√©ricos (fallback)
    SELECTORS = {
        'container': 'article, .post, .card, .item, .news-item, .athing, tr.athing',
        'title': '.titleline > a, h1, h2, h3, .title, .headline',
        'author': '.author, .byline, [rel="author"], .hnuser',
        'date': 'time, .date, .published, .age',
        'content': '.content, .description, .summary, p',
        'link': 'a[href]',
    }
    
    def __init__(
        self,
        headless: bool = False,
        browser_type: str = "chromium",
        viewport: Dict[str, int] = None,
        user_agent: str = None,
        timeout: int = 30000,
        auto_detect: bool = True
    ):
        """
        Inicializa o scraper.
        
        Args:
            headless: Se True, executa sem interface gr√°fica
            browser_type: Tipo do navegador (chromium, firefox, webkit)
            viewport: Dimens√µes da janela {'width': 1920, 'height': 1080}
            user_agent: User-Agent customizado
            timeout: Timeout padr√£o em milissegundos
            auto_detect: Se True, tenta detectar seletores automaticamente
        """
        self.headless = headless
        self.browser_type = browser_type
        self.viewport = viewport or {"width": 1920, "height": 1080}
        self.user_agent = user_agent
        self.timeout = timeout
        self.auto_detect = auto_detect
        
        self.playwright = None
        self.browser: Optional[Browser] = None
        self.context: Optional[BrowserContext] = None
        self.page: Optional[Page] = None
        
    def __enter__(self):
        """Context manager entry"""
        self.start()
        return self
        
    def __exit__(self, exc_type, exc_val, exc_tb):
        """Context manager exit"""
        self.close()
        
    def start(self, storage_state: Optional[str] = None):
        """
        Inicia o navegador e cria uma nova p√°gina.
        
        Args:
            storage_state: Caminho para arquivo JSON com cookies/auth
        """
        logger.info(f"Iniciando navegador {self.browser_type} (headless={self.headless})")
        
        self.playwright = sync_playwright().start()
        
        # Seleciona o tipo de navegador
        if self.browser_type == "chromium":
            self.browser = self.playwright.chromium.launch(headless=self.headless)
        elif self.browser_type == "firefox":
            self.browser = self.playwright.firefox.launch(headless=self.headless)
        elif self.browser_type == "webkit":
            self.browser = self.playwright.webkit.launch(headless=self.headless)
        else:
            raise ValueError(f"Tipo de navegador inv√°lido: {self.browser_type}")
        
        # Cria contexto do navegador (com ou sem storage_state)
        context_options = {
            "viewport": self.viewport,
        }
        
        if self.user_agent:
            context_options["user_agent"] = self.user_agent
            
        if storage_state:
            logger.info(f"Carregando storage_state de: {storage_state}")
            context_options["storage_state"] = storage_state
        
        self.context = self.browser.new_context(**context_options)
        self.context.set_default_timeout(self.timeout)
        
        # Cria nova p√°gina
        self.page = self.context.new_page()
        logger.info("Navegador iniciado com sucesso")
        
    def navigate(self, url: str, wait_until: str = "networkidle") -> bool:
        """
        Navega para uma URL.
        
        Args:
            url: URL de destino
            wait_until: Condi√ß√£o de espera (load, domcontentloaded, networkidle)
            
        Returns:
            True se navega√ß√£o bem-sucedida, False caso contr√°rio
        """
        logger.info(f"Navegando para: {url}")
        
        try:
            response = self.page.goto(url, wait_until=wait_until)
            
            if response and response.ok:
                logger.info(f"P√°gina carregada: {self.page.title()} (status {response.status})")
                return True
            else:
                status = response.status if response else "N/A"
                logger.error(f"Falha ao carregar p√°gina (status {status})")
                return False
                
        except Exception as e:
            logger.error(f"Erro ao navegar: {str(e)}")
            return False
    
    def scroll_to_bottom(self, pause_time: float = 1.0, max_scrolls: int = 50):
        """
        Scrolla at√© o final da p√°gina para carregar conte√∫do din√¢mico.
        
        Args:
            pause_time: Pausa entre scrolls (segundos)
            max_scrolls: N√∫mero m√°ximo de tentativas de scroll
        """
        logger.info("Iniciando scroll at√© o fim da p√°gina...")
        
        last_height = self.page.evaluate("document.body.scrollHeight")
        scrolls = 0
        
        while scrolls < max_scrolls:
            # Scrolla at√© o fim
            self.page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            
            # Aguarda carregamento
            time.sleep(pause_time)
            
            # Calcula nova altura
            new_height = self.page.evaluate("document.body.scrollHeight")
            
            # Se n√£o mudou, chegamos ao fim
            if new_height == last_height:
                logger.info(f"Fim da p√°gina alcan√ßado ap√≥s {scrolls} scrolls")
                break
                
            last_height = new_height
            scrolls += 1
            
            logger.debug(f"Scroll {scrolls}/{max_scrolls} - Altura: {new_height}px")
        
        if scrolls >= max_scrolls:
            logger.warning(f"Limite de scrolls atingido ({max_scrolls})")
    
    def extract_data(self, max_items: Optional[int] = None) -> List[Dict[str, str]]:
        """
        Extrai dados da p√°gina usando seletores gen√©ricos ou auto-detectados.
        
        Args:
            max_items: N√∫mero m√°ximo de itens para extrair
            
        Returns:
            Lista de dicion√°rios com os dados coletados
        """
        logger.info("Iniciando extra√ß√£o de dados...")
        
        # Auto-detec√ß√£o de seletores se habilitado
        if self.auto_detect:
            try:
                logger.info("üîç Tentando auto-detectar seletores...")
                detected_selectors = auto_detect_selectors(self.page)
                
                # Atualiza seletores com os detectados
                for key, value in detected_selectors.items():
                    if value:
                        self.SELECTORS[key] = value
                
                logger.info("‚úÖ Seletores auto-detectados aplicados")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Auto-detec√ß√£o falhou, usando seletores padr√£o: {str(e)}")
        
        data = []
        
        try:
            # Busca todos os containers de conte√∫do
            containers = self.page.query_selector_all(self.SELECTORS['container'])
            logger.info(f"Encontrados {len(containers)} containers na p√°gina")
            
            # Se n√£o achou nada, tenta fallback
            if len(containers) == 0:
                logger.warning("‚ö†Ô∏è Nenhum container encontrado com seletores atuais")
                logger.info("üîÑ Tentando seletores alternativos...")
                
                # Tenta tags sem√¢nticas b√°sicas
                fallback_selectors = ['article', 'section', 'div[class*="post"]', 'div[class*="item"]']
                for selector in fallback_selectors:
                    containers = self.page.query_selector_all(selector)
                    if len(containers) > 0:
                        logger.info(f"‚úÖ Encontrados {len(containers)} com {selector}")
                        break
            
            # Limita quantidade se especificado
            if max_items:
                containers = containers[:max_items]
            
            for idx, container in enumerate(containers, 1):
                try:
                    item = self._extract_item_data(container)
                    
                    # S√≥ adiciona se tiver pelo menos t√≠tulo ou link
                    if item.get('title') or item.get('link'):
                        data.append(item)
                        logger.debug(f"Item {idx} extra√≠do: {item.get('title', 'Sem t√≠tulo')[:50]}")
                    
                except Exception as e:
                    logger.warning(f"Erro ao extrair item {idx}: {str(e)}")
                    continue
            
            logger.info(f"Extra√ß√£o conclu√≠da: {len(data)} itens coletados")
            
        except Exception as e:
            logger.error(f"Erro durante extra√ß√£o de dados: {str(e)}")
        
        return data
    
    def _extract_item_data(self, container) -> Dict[str, str]:
        """
        Extrai dados de um container espec√≠fico.
        
        Args:
            container: ElementHandle do container
            
        Returns:
            Dicion√°rio com os dados extra√≠dos
        """
        item = {}
        
        # Extrai t√≠tulo (tenta .titleline > a primeiro, depois fallback para outros)
        title_el = container.query_selector('.titleline > a')
        if not title_el:
            title_el = container.query_selector(self.SELECTORS['title'])
        if title_el:
            item['title'] = title_el.inner_text().strip()
            # Pega o link do t√≠tulo tamb√©m
            href = title_el.get_attribute('href')
            if href:
                item['link'] = self.page.evaluate(
                    f"new URL('{href}', window.location.href).href"
                )
        
        # Extrai autor
        author_el = container.query_selector(self.SELECTORS['author'])
        if author_el:
            item['author'] = author_el.inner_text().strip()
        
        # Extrai data
        date_el = container.query_selector(self.SELECTORS['date'])
        if date_el:
            # Tenta pegar atributo datetime primeiro
            date_value = date_el.get_attribute('datetime')
            if not date_value:
                date_value = date_el.inner_text().strip()
            item['date'] = date_value
        
        # Extrai conte√∫do/descri√ß√£o
        content_el = container.query_selector(self.SELECTORS['content'])
        if content_el:
            item['content'] = content_el.inner_text().strip()
        
        # Extrai link (apenas se ainda n√£o tiver do t√≠tulo)
        if 'link' not in item:
            link_el = container.query_selector(self.SELECTORS['link'])
            if link_el:
                href = link_el.get_attribute('href')
                if href:
                    # Converte link relativo em absoluto
                    item['link'] = self.page.evaluate(
                        f"new URL('{href}', window.location.href).href"
                    )
        
        return item
    
    def screenshot(self, path: str = "screenshot.png"):
        """
        Captura screenshot da p√°gina atual.
        
        Args:
            path: Caminho para salvar a imagem
        """
        try:
            self.page.screenshot(path=path, full_page=True)
            logger.info(f"Screenshot salvo em: {path}")
        except Exception as e:
            logger.error(f"Erro ao capturar screenshot: {str(e)}")
    
    def close(self):
        """Fecha o navegador e libera recursos"""
        logger.info("Fechando navegador...")
        
        if self.page:
            self.page.close()
        if self.context:
            self.context.close()
        if self.browser:
            self.browser.close()
        if self.playwright:
            self.playwright.stop()
            
        logger.info("Navegador fechado")


def scrape(
    url: str,
    headless: bool = False,
    storage_state: Optional[str] = None,
    scroll: bool = True,
    max_items: Optional[int] = None
) -> List[Dict[str, str]]:
    """
    Fun√ß√£o helper para scraping simples.
    
    Args:
        url: URL alvo
        headless: Se True, executa sem interface
        storage_state: Caminho para arquivo de autentica√ß√£o
        scroll: Se True, scrolla at√© o fim da p√°gina
        max_items: N√∫mero m√°ximo de itens
        
    Returns:
        Lista de dicion√°rios com dados coletados
    """
    with WebScraper(headless=headless) as scraper:
        scraper.start(storage_state=storage_state)
        
        if not scraper.navigate(url):
            return []
        
        if scroll:
            scraper.scroll_to_bottom()
        
        return scraper.extract_data(max_items=max_items)
