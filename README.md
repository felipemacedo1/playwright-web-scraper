# ğŸ•·ï¸ Playwright Web Scraper

> Web Scraping profissional com Playwright - Coleta, armazena e refina dados de qualquer site

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![Playwright](https://img.shields.io/badge/Playwright-1.40+-green.svg)](https://playwright.dev/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

## ğŸ“‹ Sobre o Projeto

Um web scraper robusto e flexÃ­vel construÃ­do com Playwright que permite:
- ğŸŒ Coletar dados de qualquer site de forma automatizada
- ğŸ’¾ Salvar resultados em CSV e SQLite
- ğŸ” Suporte a login com autenticaÃ§Ã£o persistente
- ğŸ¤– Refinar dados com IA (OpenAI) - opcional
- ğŸ“Š Sistema de logs e tratamento de erros
- ğŸ³ Containerizado com Docker

## ğŸ¯ Casos de Uso

- Monitorar preÃ§os de produtos
- Coletar artigos e notÃ­cias
- Extrair dados de vagas de emprego
- Scraping de redes sociais
- AnÃ¡lise de concorrÃªncia
- Coleta de dados pÃºblicos

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.8+
- pip

### Passo a Passo

```bash
# Clone o repositÃ³rio
git clone https://github.com/felipemacedo1/playwright-web-scraper.git
cd playwright-web-scraper

# Crie um ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Instale as dependÃªncias
pip install -r requirements.txt

# Instale os navegadores do Playwright
playwright install chromium
```

### ConfiguraÃ§Ã£o

```bash
# Copie o arquivo de exemplo
cp .env.example .env

# Edite o .env com suas configuraÃ§Ãµes
nano .env
```

## ğŸ® Como Usar

### 1. Scraping BÃ¡sico

```bash
python main.py --url "https://example.com" --output data/results.csv
```

### 2. Com Login Manual

Primeiro, salve seu estado de autenticaÃ§Ã£o:

```bash
python save_storage.py --url "https://example.com/login"
```

Isso abrirÃ¡ o navegador. FaÃ§a login manualmente e feche o navegador. O estado serÃ¡ salvo em `storage_state.json`.

Depois execute o scraper com autenticaÃ§Ã£o:

```bash
python main.py --url "https://example.com" --use-storage
```

### 3. Modo Headless

```bash
python main.py --url "https://example.com" --headless
```

### 4. Com Refinamento de IA (OpenAI)

```bash
# Configure sua API key no .env
OPENAI_API_KEY=sk-your-key-here

# Execute com refinamento
python main.py --url "https://example.com" --refine
```

### 5. Salvando em SQLite

```bash
python main.py --url "https://example.com" --database data/scraping.db
```

## ğŸ“ Estrutura do Projeto

```
playwright-web-scraper/
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ scraper.py          # LÃ³gica principal de scraping
â”‚   â”œâ”€â”€ storage.py          # Salvamento em CSV/SQLite
â”‚   â””â”€â”€ llm_refiner.py      # Refinamento com IA (opcional)
â”œâ”€â”€ data/                   # Dados coletados
â”œâ”€â”€ logs/                   # Arquivos de log
â”œâ”€â”€ save_storage.py         # Gerador de storage_state.json
â”œâ”€â”€ main.py                 # Script principal
â”œâ”€â”€ requirements.txt        # DependÃªncias Python
â”œâ”€â”€ .env.example            # Exemplo de configuraÃ§Ã£o
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Dockerfile              # Container Docker
â””â”€â”€ README.md
```

## âš™ï¸ ConfiguraÃ§Ãµes AvanÃ§adas

### VariÃ¡veis de Ambiente (.env)

```env
# Navegador
BROWSER_TYPE=chromium
HEADLESS=false
VIEWPORT_WIDTH=1920
VIEWPORT_HEIGHT=1080
USER_AGENT=Mozilla/5.0...

# Timeouts (ms)
NAVIGATION_TIMEOUT=30000
DEFAULT_TIMEOUT=10000

# OpenAI (opcional)
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4o-mini

# Logging
LOG_LEVEL=INFO
```

### Personalizar Seletores

Edite `agent/scraper.py` e ajuste os seletores CSS para o site alvo:

```python
# Exemplo para site de notÃ­cias
SELECTORS = {
    'container': 'article, .post, .news-item',
    'title': 'h1, h2, .title',
    'author': '.author, .byline',
    'date': 'time, .date',
    'content': '.content, .article-body',
    'link': 'a[href]'
}
```

## ğŸ³ Docker

### Build

```bash
docker build -t playwright-scraper .
```

### Run

```bash
docker run -v $(pwd)/data:/app/data playwright-scraper \
  --url "https://example.com" --output /app/data/results.csv
```

## ğŸ“Š Exemplos de Output

### CSV

```csv
title,author,date,link,content
"Artigo Exemplo","JoÃ£o Silva","2025-01-11","https://...","ConteÃºdo do artigo..."
```

### SQLite

```sql
CREATE TABLE scraped_data (
    id INTEGER PRIMARY KEY,
    title TEXT,
    author TEXT,
    date TEXT,
    link TEXT UNIQUE,
    content TEXT,
    scraped_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

## ğŸ”§ Argumentos do CLI

```bash
python main.py [opÃ§Ãµes]

OpÃ§Ãµes:
  --url URL              URL alvo para scraping (obrigatÃ³rio)
  --output FILE          Caminho do arquivo CSV de saÃ­da
  --database FILE        Caminho do banco SQLite
  --use-storage          Usa storage_state.json para autenticaÃ§Ã£o
  --headless             Executa em modo headless (sem interface)
  --refine               Refina dados coletados com IA
  --max-items N          NÃºmero mÃ¡ximo de itens para coletar
  --scroll-pause SEC     Pausa entre scrolls (segundos)
```

## ğŸ›¡ï¸ Boas PrÃ¡ticas

### Respeite os Sites
- âœ… Leia e respeite o `robots.txt`
- âœ… Implemente delays entre requisiÃ§Ãµes
- âœ… NÃ£o sobrecarregue servidores
- âœ… Respeite termos de uso

### Anti-DetecÃ§Ã£o
- âœ… Rotate user agents
- âœ… Use proxies quando necessÃ¡rio
- âœ… Simule comportamento humano (scrolls, pauses)
- âœ… Evite padrÃµes Ã³bvios de bot

### SeguranÃ§a
- âš ï¸ Nunca commite `storage_state.json` ou `.env`
- âš ï¸ Use variÃ¡veis de ambiente para secrets
- âš ï¸ Sanitize dados antes de salvar

## ğŸ§ª Testes

```bash
# Execute os testes
pytest tests/

# Com cobertura
pytest --cov=agent tests/
```

## ğŸ› Troubleshooting

### Erro: "Browser not found"

```bash
playwright install chromium
```

### Erro: "Navigation timeout"

Aumente o timeout no `.env`:
```env
NAVIGATION_TIMEOUT=60000
```

### Erro: "Element not found"

Verifique os seletores CSS em `agent/scraper.py` e ajuste para o site alvo.

### Site detecta como bot

- Use `--use-storage` para cookies persistentes
- Adicione delays: `--scroll-pause 2`
- Configure user-agent no `.env`

## ğŸ“š Recursos

- [Playwright Documentation](https://playwright.dev/python/)
- [CSS Selectors Reference](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Selectors)
- [Web Scraping Best Practices](https://www.scrapehero.com/web-scraping-best-practices/)

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/NovaFuncionalidade`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona funcionalidade X'`)
4. Push para a branch (`git push origin feature/NovaFuncionalidade`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja [LICENSE](LICENSE) para mais detalhes.

## âš ï¸ Disclaimer

Este projeto Ã© para fins educacionais. O uso de web scraping deve respeitar os termos de serviÃ§o dos sites e as leis aplicÃ¡veis (LGPD, GDPR, etc.). O autor nÃ£o se responsabiliza pelo uso indevido desta ferramenta.

---

**Desenvolvido por Felipe Macedo** | [GitHub](https://github.com/felipemacedo1)

â­ Se este projeto foi Ãºtil, considere dar uma estrela!
